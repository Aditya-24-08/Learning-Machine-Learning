This folder presents the idea of cross validation, but not like
the extreme example of leave one out but infact five fold
cross validation which actually takes 80% of the data and
trains a model out of it and then uses this model to get
predictons out of the remaining 20% data, this five fold cross
validation can be extended to ten fold too or to similar ideas,
although five and ten fold cross validations are quite popular
because they almost correctly and reliably estimate of how
the models would generalize. Just one more thing to keep in
mind is that one should not take the data from a particular
category or class, or infact, should take it randomly in order
to train the models to different types of data to generalize
in a better way. 